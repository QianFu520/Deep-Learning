{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290997ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp38-cp38-win_amd64.whl (192.3 MB)\n",
      "     -------------------------------------- 192.3/192.3 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.0-cp38-cp38-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torch) (2.8.6)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "     -------------------------------------- 166.4/166.4 kB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\qfu88\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, fsspec, filelock, torch, torchvision\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.10.0 mpmath-1.3.0 sympy-1.12 torch-2.1.0 torchvision-0.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a07eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a05d4c",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "This is an example of building a torch data loader for a dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3a9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('Data/small_file.csv')\n",
    "test_csv=pd.read_csv('Data/test.csv')\n",
    "valid_csv=pd.read_csv('Data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9bcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "        self.images = self.images/256\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9ba95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "val_set = FashionDataset(valid_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a088e0",
   "metadata": {},
   "source": [
    "## Build a MLP\n",
    "\n",
    "The number of input is decided by the images which is 28*28 = 784, the number of output is 10 which is 0 to 9. The size of hidden layer is a tunable hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d90692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,num_inputs=784,num_outputs=10,num_hiddens=256):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.hidden = nn.Linear(num_inputs, num_hiddens)\n",
    "        \n",
    "        self.output = nn.Linear(num_hiddens, num_outputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "       \n",
    "        X = X.view(X.size(0), -1)\n",
    "        \n",
    "        X = F.relu(self.hidden(X))\n",
    "        \n",
    "        X = self.output(X)\n",
    "\n",
    "        return X\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe80fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model performance\n",
    "def eval_model(model,data_loader):\n",
    "    model.eval()\n",
    "    y_true_list=[]\n",
    "    y_pred_list=[]\n",
    "    model.eval()\n",
    "    for x,y in data_loader:\n",
    "        outputs=model(x)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        y_pred_list.extend(y_pred.clone().detach().tolist())\n",
    "        y_true_list.extend(y.clone().detach().tolist())\n",
    "    acc=classification_report(y_true_list, y_pred_list,output_dict=True)['accuracy']\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cff63",
   "metadata": {},
   "source": [
    "## Train the MLP \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f633ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 3407\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# hyperparameter values to consider.\n",
    "hiddens=[256,512,1024]\n",
    "lrs=[5e-2, 1e-1, 5e-1]\n",
    "num_inputs=784\n",
    "num_outputs=10\n",
    "#loss function we gonna use \n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e664c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.6701\n",
      "Epoch 5, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.7885\n",
      "Epoch 10, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.7976\n",
      "Epoch 15, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.8035\n",
      "Epoch 20, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.8102\n",
      "Epoch 25, Hidden units: 256, Learning rate: 0.05, Accuracy: 0.8192\n",
      "Epoch 0, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.7050\n",
      "Epoch 5, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.7818\n",
      "Epoch 10, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.8007\n",
      "Epoch 15, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.8132\n",
      "Epoch 20, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.8238\n",
      "Epoch 25, Hidden units: 256, Learning rate: 0.1, Accuracy: 0.8312\n",
      "Epoch 0, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.5874\n",
      "Epoch 5, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.8117\n",
      "Epoch 10, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.8292\n",
      "Epoch 15, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.8428\n",
      "Epoch 20, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.8526\n",
      "Epoch 25, Hidden units: 256, Learning rate: 0.5, Accuracy: 0.8606\n",
      "Epoch 0, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.6761\n",
      "Epoch 5, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.7881\n",
      "Epoch 10, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.7983\n",
      "Epoch 15, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.8064\n",
      "Epoch 20, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.8125\n",
      "Epoch 25, Hidden units: 512, Learning rate: 0.05, Accuracy: 0.8207\n",
      "Epoch 0, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.7093\n",
      "Epoch 5, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.7810\n",
      "Epoch 10, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.7987\n",
      "Epoch 15, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.8108\n",
      "Epoch 20, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.8220\n",
      "Epoch 25, Hidden units: 512, Learning rate: 0.1, Accuracy: 0.8309\n",
      "Epoch 0, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.5553\n",
      "Epoch 5, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.8060\n",
      "Epoch 10, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.8377\n",
      "Epoch 15, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.8505\n",
      "Epoch 20, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.8559\n",
      "Epoch 25, Hidden units: 512, Learning rate: 0.5, Accuracy: 0.8529\n",
      "Epoch 0, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.7036\n",
      "Epoch 5, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.7896\n",
      "Epoch 10, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.8000\n",
      "Epoch 15, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.8075\n",
      "Epoch 20, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.8145\n",
      "Epoch 25, Hidden units: 1024, Learning rate: 0.05, Accuracy: 0.8213\n",
      "Epoch 0, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.7160\n",
      "Epoch 5, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.7865\n",
      "Epoch 10, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.8014\n",
      "Epoch 15, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.8149\n",
      "Epoch 20, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.8261\n",
      "Epoch 25, Hidden units: 1024, Learning rate: 0.1, Accuracy: 0.8347\n",
      "Epoch 0, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.6564\n",
      "Epoch 5, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.8264\n",
      "Epoch 10, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.8459\n",
      "Epoch 15, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.8535\n",
      "Epoch 20, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.8604\n",
      "Epoch 25, Hidden units: 1024, Learning rate: 0.5, Accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "current_best=0.0\n",
    "best_model=None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for h in hiddens:\n",
    "    for lr in lrs:\n",
    "      \n",
    "        \n",
    "        model = MLP(num_inputs=num_inputs, num_outputs=num_outputs, num_hiddens=h)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(30):\n",
    "           \n",
    "            model.train()\n",
    "           \n",
    "            for x,y in train_loader:\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(x)\n",
    "                \n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "            if i%5 == 0:\n",
    "                accuracy = eval_model(model, val_loader)\n",
    "                print(f\"Epoch {i}, Hidden units: {h}, Learning rate: {lr}, Accuracy: {accuracy:.4f}\")\n",
    "                # Check if current accuracy is greater than the previous best\n",
    "                if accuracy > current_best:\n",
    "                    current_best = accuracy\n",
    "                    best_model = model\n",
    "                    \n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
